{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fc9086-93aa-4645-8ba2-380c3acbbed9",
   "metadata": {},
   "source": [
    "# Level 4: Agentic RAG\n",
    "\n",
    "This tutorial presents an example of executing queries with agentic RAG in Llama Stack. It shows how to initialize an agent with the RAG tool provided by Llama Stack and to invoke it such that retrieval from a vector DB is activated when necessary. The tutorial also covers document ingestion using the RAG tool.\n",
    "For a foundational (non-agentic) RAG tutorial, please refer to [Level1_foundational_RAG.ipynb](demos/rag_agentic/notebooks/Level1_foundational_RAG.ipynb).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers the following steps:\n",
    "1. Connecting to a llama-stack server.\n",
    "2. Indexing a collection of documents in a vector DB for later retrieval.\n",
    "3. Initializing the agent capable of retrieving content from vector DB via tool use.\n",
    "4. Launching the agent and using it to answer user queries during the inference step.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have a running instance of the Llama Stack server (local or remote) with at least one preconfigured vector DB. For more information, please refer to the corresponding [Llama Stack tutorials](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html).\n",
    "\n",
    "## Setting the Environment Variables\n",
    "\n",
    "Use the [`.env.example`](../../../.env.example) to create a new file called `.env` and ensure you add all the relevant environment variables below.\n",
    "\n",
    "In addition to the environment variables listed in the [\"Getting Started\" notebook](demos/rag_agentic/notebooks/Level0_getting_started_with_Llama_Stack.ipynb), the following should be provided for this demo to run:\n",
    " - `VDB_PROVIDER`: the vector DB provider to be used. Must be supported by Llama Stack. For this demo, we use Milvus Lite which is our preferred solution.\n",
    " - `VDB_EMBEDDING`: the embedding model to be used for ingestion and retrieval. For this demo, we use all-MiniLM-L6-v2.\n",
    " - `VDB_EMBEDDING_DIMENSION` (optional): the dimension of the embedding. Defaults to 384.\n",
    " - `VECTOR_DB_CHUNK_SIZE` (optional): the chunk size for the vector DB. Defaults to 512."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db34e4b-ed29-4007-b760-59543d4caca1",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "We will start with a few imports needed for this demo only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854e7cb4-aed9-4098-adc1-a66f4c9e6ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from llama_stack_client import Agent, AgentEventLogger, RAGDocument\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab4244-e7af-405b-b0c3-4bf00411f26e",
   "metadata": {},
   "source": [
    "Next, we will initialize our environment as described in detail in our [\"Getting Started\" notebook](demos/rag_agentic/notebooks/Level0_getting_started_with_Llama_Stack.ipynb). Please refer to it for additional explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b87b139-bd18-47b2-889a-1b8ed3018655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server @ http://localhost:8321\n",
      "Inference Parameters:\n",
      "\tModel: ibm-granite/granite-3.2-8b-instruct\n",
      "\tSampling Parameters: {'strategy': {'type': 'greedy'}, 'max_tokens': 4096}\n",
      "\tstream: True\n"
     ]
    }
   ],
   "source": [
    "# for accessing the environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# for communication with Llama Stack\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "# pretty print of the results returned from the model/agent\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from src.utils import step_printer\n",
    "from termcolor import cprint\n",
    "\n",
    "remote = os.getenv(\"REMOTE\", \"True\")\n",
    "\n",
    "if remote == \"False\":\n",
    "    local_port = os.getenv(\"LOCAL_SERVER_PORT\", 8321)\n",
    "    base_url = f\"http://localhost:{local_port}\"\n",
    "else: # any value non equal to 'False' will be considered as 'True'\n",
    "    base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "\n",
    "\n",
    "# Tavily search API key is required for some of our demos and must be provided to the client upon initialization.\n",
    "# We will cover it in the agentic demos that use the respective tool. Please ignore this parameter for all other demos.\n",
    "tavily_search_api_key = os.getenv(\"TAVILY_SEARCH_API_KEY\")\n",
    "if tavily_search_api_key is None:\n",
    "    provider_data = None\n",
    "else:\n",
    "    provider_data = {\"tavily_search_api_key\": tavily_search_api_key}\n",
    "\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data=provider_data\n",
    ")\n",
    "    \n",
    "print(f\"Connected to Llama Stack server @ {base_url}\")\n",
    "\n",
    "# model_id will later be used to pass the name of the desired inference model to Llama Stack Agents/Inference APIs\n",
    "model_id = os.getenv(\"INFERENCE_MODEL_ID\")\n",
    "\n",
    "temperature = float(os.getenv(\"TEMPERATURE\", 0.0))\n",
    "if temperature > 0.0:\n",
    "    top_p = float(os.getenv(\"TOP_P\", 0.95))\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": temperature, \"top_p\": top_p}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "max_tokens = int(os.getenv(\"MAX_TOKENS\", 4096))\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "stream_env = os.getenv(\"STREAM\", \"True\")\n",
    "# the Boolean 'stream' parameter will later be passed to Llama Stack Agents/Inference APIs\n",
    "# any value non equal to 'False' will be considered as 'True'\n",
    "stream = (stream_env != \"False\")\n",
    "\n",
    "print(f\"Inference Parameters:\\n\\tModel: {model_id}\\n\\tSampling Parameters: {sampling_params}\\n\\tstream: {stream}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357655b5-cade-46f4-9f57-be5dcef9abc2",
   "metadata": {},
   "source": [
    "Finally, we will initialize the document collection to be used for RAG ingestion and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583421f3-5c77-4964-b525-12f967c20816",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203de51-f570-44ab-8130-36333a54888b",
   "metadata": {},
   "source": [
    "## 2. Indexing the Documents\n",
    "- Initialize a new document collection in the target vector DB. All parameters related to the vector DB, such as the embedding model and dimension, must be specified here.\n",
    "- Provide a list of document URLs to the RAG tool. Llama Stack will handle fetching, conversion and chunking of the documents' content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dd4664a-ff7f-4474-b6af-3a4ad3f73052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define and register the document collection to be used\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=os.getenv(\"VDB_EMBEDDING\"),\n",
    "    embedding_dimension=int(os.getenv(\"VDB_EMBEDDING_DIMENSION\", 384)),\n",
    "    provider_id=os.getenv(\"VDB_PROVIDER\"),\n",
    ")\n",
    "\n",
    "# ingest the documents into the newly created document collection\n",
    "urls = [\n",
    "    (\"https://www.openshift.guide/openshift-guide-screen.pdf\", \"application/pdf\"),\n",
    "]\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=url,\n",
    "        mime_type=url_type,\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, (url, url_type) in enumerate(urls)\n",
    "]\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=int(os.getenv(\"VECTOR_DB_CHUNK_SIZE\", 512)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5639413-90d6-42ae-add4-6c89da0297e2",
   "metadata": {},
   "source": [
    "## 3. Executing queries via the RAG-aware agent\n",
    "- Initialize an agent with a list of tools including the built-in RAG tool. The RAG tool specification must include a list of document collection IDs to retrieve from.\n",
    "- For each prompt, initialize a new agent session, execute a turn during which a retrieval call may be requested, and output the reply received from the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b9baa2-4739-426a-b79a-2ff90f44c023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "User> How to install OpenShift?\u001b[0m\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[33mTool call: knowledge_search, Arguments: {'query': 'installing OpenShift'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 1:\\nDocument_id:num-0\\nContent:  We\\nrecommend you to check the official Red Hat OpenShift Local documentation for an updated list of\\nrequirements at the official documentation website.\\n\\uf05a\\nRegarding Linux, even if Red Hat does not officially support them, OpenShift Local\\ncan run on other distributions, such as Ubuntu or Debian, with minor caveats.\\nRunning OpenShift Local on any Linux distribution requires a few additional\\nsoftware packages to be installed through your default package manager. The\\n15\\ndocumentation at crc.dev/crc has more information about this subject.\\n7.2. Hardware Requirements\\nIn terms of hardware, OpenShift Local has some strict requirements. Your system must use a recent\\nIntel CPU (except for Macs, where Apple Silicon machines are supported) with at least four physical\\ncores and have at least 16 GB of RAM. Be aware that the base installation of OpenShift Local\\nrequires at least 9 GB free to start. Of course, to run other applications on OpenShift Local, you will\\nneed more RAM, so using a computer with at least 32 GB of RAM is strongly recommended.\\nOpenShift Local also requires at least 35 GB of free disk space for its installation. The memory\\nrequirements are likely to increase in the future, so please check the documentation at crc.dev for\\nmore up-to-date information.\\n7.3. Installation\\nTo install OpenShift Local, open your web browser and navigate to console.redhat.com/openshift/\\ncreate/local . Download the latest release of OpenShift Local and the \"pull secret\" file. The latter is a\\nfile containing a key identifying your copy of OpenShift Local to your Red Hat Developer account.\\nUnzip the file containing the OpenShift Local executable, and using your terminal, run the\\ncommand crc setup . This command will prepare your copy of OpenShift Local, verifying\\nrequirements and setting the required configuration values.\\nOnce the crc setup command is ready, launch crc start. Running crc start can take a long time,\\naround 20 minutes, on a recent PC.\\nOnce started, access the OpenShift Web Console with the crc console command, which will open\\nyour default browser. OpenShift Local uses the developer username and password to log in as a\\nlow-privilege user, while the kubeadmin user uses a random-generated password. Use the crc\\nconsole --credentials command to find the credentials required to log in as the kubeadmin user.\\nOpenShift Local allows developers to perform various everyday tasks as if it were a standard\\nOpenShift cluster, like deploying applications\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 2:\\nDocument_id:num-0\\nContent: .\\nThese characteristics set OpenShift apart as an excellent Kubernetes platform for enterprise users.\\nThe latest version of OpenShift available at the time of this writing is 4.12.\\n3.2. Is Red Hat OpenShift Open Source?\\nRed Hat OpenShift is a commercial product based on an open-source project called OKD. This\\nacronym means \" OpenShift Kubernetes Distribution\" and is publicly available for everyone to\\ninspect and contribute. Like the upstream Kubernetes project, OKD developers use the Go\\nprogramming language.\\n3.3. How can I run OpenShift?\\nToday, Red Hat OpenShift is available through various mechanisms and formats:\\n• DevOps teams can install it in their data centers \"on-premise.\"\\n• Major hyperscalers such as AWS, Azure, Google Cloud Platform, and IBM Cloud offer managed\\nRed Hat OpenShift installations.\\n• Developers can either run OpenShift locally on their workstations using Red Hat OpenShift\\nLocal, also known as CRC or \"Code-Ready Containers\"\\n• They can also request a 30-day trial OpenShift cluster, offered by Red Hat, at no charge, for\\ntesting and evaluation purposes.\\nRed Hat OpenShift is an integrated Platform-as-a-Service for enterprise users based on Kubernetes.\\nIt is tightly integrated with advanced security settings, developer tooling, and monitoring\\nmechanisms, allowing DevOps teams to be more productive.\\n8\\nChapter 4. OpenShift-only Custom Resource\\nDefinitions\\nRed Hat OpenShift is a complete DevOps platform extending Kubernetes in various ways. It bundles\\na constellation of Custom Resource Definitions (CRDs) to make the life of developers and cluster\\nadministrators easier.\\nLet us talk first about the CRDs only available on OpenShift.\\n4.1. Project\\nAn OpenShift Project is similar to a Kubernetes namespace, but more tightly integrated into the\\nsecurity system of OpenShift through additional annotations.\\napiVersion: project.openshift.io/v1\\nkind: Project\\nmetadata:\\n\\xa0 name: linkedin-learning-project\\n\\xa0 annotations:\\n\\xa0   openshift.io/description: \"Project description\"\\n\\xa0   openshift.io/display-name: \"Display name\"\\n4.2. Route\\nThe OpenShift Route object was one of the primary inspirations during the development of the\\nIngress object. In OpenShift, Ingress and Route objects work together to ensure your applications\\nare available outside the cluster.\\napiVersion: route.openshift.io/v1\\nkind: Route\\nmetadata:\\n\\xa0 name: my-route\\nspec:\\n\\xa0 host:\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 3:\\nDocument_id:num-0\\nContent:  \"Import from Git\" entry. Click on it, and paste the URL of a project, for example,\\ngitlab.com/akosma/simple-deno-api.git.\\nAs soon as you paste the URL, OpenShift will immediately analyze the structure and programming\\nlanguage of the project and automatically recommend options for its build process. In our case, it’s\\na small application built with the Go programming language, and as such, it will advise the options\\nshown on the screen.\\nFigure 5. Deploying a project directly from its Git repository\\n25\\nThis particular example doesn’t require more configurations than the ones shown on the screen;\\nclick the [\\u2009Create\\u2009] button.\\nAfter a few seconds, you will see your application running on the \"Topology\" screen. OpenShift will\\ndownload the source code and trigger your project’s build. Click on the Topology screen icon to see\\nthe \"Build\" section, indicating that a build is running. The compilation and deployment of your\\napplication can take some time, depending on the complexity of the source code and the\\nprogramming language used.\\nOnce the build has finished, on the same pane, you will see a route available under the \"Routes\"\\nsection. Click on it, and you will see your application in action.\\n10.2. Container Registry\\nOpenShift has built your application source code, and the product of this build process is a\\ncontainer. You can see the container that OpenShift made for you on the \"Administrator\"\\nperspective, selecting the \"Builds\" menu and then the \"ImageStreams\" menu entry.\\nOpenShift includes a container registry; developers can use it as any other registry from outside the\\ncluster. Let us use \"podman\" to access the container registry and run the container locally on your\\nworkstation.\\nUsers must have the \"registry-editor\" and the \"system:image-builder\" roles to access the container\\nregistry. Since we’re connected to the Web Console using the \"kubeadmin\" user, we can provide\\nthose roles directly from the user interface without using the command line.\\nNavigate to the \"User Management\" section and select \"RoleBindings.\" Click on the [\\u2009Create\\nbinding\\u2009] button, and fill the form using the following values:\\n• Name: developer-sourcecode-registry-editor\\n• Namespace: sourcecode\\n• Role name: registry-editor\\n• Subject: User\\n• Subject name: developer\\nDo the same for the \"system:image-builder\" role, using a different \"Name\" field\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 4:\\nDocument_id:num-0\\nContent: 23\\ninstall OpenShift Local, 16\\nJ\\nJAR file, 23\\nJava, 14, 24, 44\\nJavaScript, 24, 44\\nJenkins, 28\\nK\\nKiali, 36\\nKibana, 40, 40\\nKnative, 34\\nKubernetes, 7\\nL\\nlogs, 40\\nM\\nMicroservices, 36\\nmonitor, 40\\nN\\nNode.js, 14\\nnon-root accounts, 20\\nO\\nOpenShift 4.12, 33\\nOpenShift Kubernetes Distribution, 8\\nOpenShift Service Mesh, 36\\noperator, 28, 36\\nOperatorHub, 33, 36\\nOperators, 33\\n48\\nP\\nperspectives, 22\\nPHP, 14, 24\\nPlatform-as-a-Service, 8\\nprivilege escalation, 19\\nprivileged ports, 20\\nProject, 9\\nPrometheus, 40, 44\\nPromQL, 45\\nPython, 14, 24, 44\\nQ\\nQuarkus, 14, 44\\nR\\nRed Hat developer account, 13\\nRed Hat OpenShift, 7\\nRed Hat OpenShift Dev Spaces, 14\\nRed Hat OpenShift Local, 8, 15\\nRed Hat OpenShift Pipelines, 28\\nRed Hat Quay, 20\\nRed Hat Universal Base Images, 19\\nrole, 19\\nRoute, 9\\nRust, 14\\nS\\nScala, 14\\nScaling, 42\\nsecure by default, 19\\nSecurity Context Constraints, 19\\nServerless, 34\\nservice mesh, 36\\nsource code project, 22\\nstateful applications, 33\\nT\\nTekton, 28\\ntemplates, 32\\nTopology, 27\\nTwelve-Factor App, 21, 40\\nTypeScript, 24\\nU\\nUBI, 19\\nV\\nVertical scaling, 42\\nVisual Studio Code, 14\\nW\\nWeb Console, 22, 40\\n49\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 5:\\nDocument_id:num-0\\nContent:  Git repository, for example, but not\\n22\\nlimited to GitHub, GitLab, Gitea, or other locations.\\n• Importing YAML directly or even a JAR file with a Java application.\\nLet us select the \"Container Image\" option, where we can specify the URL of a ready-to-use\\ncontainer.\\nEnter the URL of the container on the field, and click on the [\\u2009Create\\u2009] button at the bottom of the\\npage. You do not need to change any other value on the form.\\nA few seconds later, depending on the size of the container and the speed of your Internet\\nconnection, OpenShift will have pulled the container and deployed it onto your cluster. This\\ndeployment will include the usual standard elements: a \"Deployment\" object, a \"Service\" object, and\\na \"Route.\"\\nOpenShift offers a visual representation of the applications running on your project: click on the\\nicon of your container, and you will see a panel opening on the right side of the screen. This panel\\nwill include the URL automatically assigned to your deployment, and clicking it will show the\\napplication in action in another browser tab.\\nFigure 4. Topology screen on Red Hat OpenShift\\n9.2. Creating and Debugging Applications with the odo\\nTool\\nWith the oc tool, Red Hat provides another one geared toward software developers: the odo tool.\\nDevelopers can use the odo tool to create applications using \"Devfiles,\" particular files named\\n\"devfile.yaml\" based on an open standard available at the Devfiles website. Devfiles contain\\ninformation about your application’s programming language, dependencies, and other essential\\ndetails.\\n23\\nThe odo tool is not available by default on your command line, but you can download it from the\\n\"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry. Click on the\\n\"Download odo\" link at the bottom, and select the version of odo that corresponds to your system.\\nThe \"odo catalog list components was\" command shows the various programming languages and\\nframeworks supported off-the-box by \"odo.\"\\nThe odo init  command prompts the user for a new application using many programming\\nlanguages: .NET, Go, Java, JavaScript, PHP, Python, and TypeScript. The last command generates a\\nscaffold ready to be populated with the required logic. Finally, the odo push command builds and\\npushes the container to the OpenShift container registry, deploying\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'END of knowledge_search tool results.\\n'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The above results were retrieved to help answer the user\\'s query: \"installing OpenShift\". Use them as supporting information only in answering this query.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 1:\\nDocument_id:num-0\\nContent:  We\\nrecommend you to check the official Red Hat OpenShift Local documentation for an updated list of\\nrequirements at the official documentation website.\\n\\uf05a\\nRegarding Linux, even if Red Hat does not officially support them, OpenShift Local\\ncan run on other distributions, such as Ubuntu or Debian, with minor caveats.\\nRunning OpenShift Local on any Linux distribution requires a few additional\\nsoftware packages to be installed through your default package manager. The\\n15\\ndocumentation at crc.dev/crc has more information about this subject.\\n7.2. Hardware Requirements\\nIn terms of hardware, OpenShift Local has some strict requirements. Your system must use a recent\\nIntel CPU \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexcept for Macs, where Apple Silicon machines are supported\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with at least four physical\\ncores and have at least 16 GB of RAM. Be aware that the base installation of OpenShift Local\\nrequires at least 9 GB free to start. Of course, to run other applications on OpenShift Local, you will\\nneed more RAM, so using a computer with at least 32 GB of RAM is strongly recommended.\\nOpenShift Local also requires at least 35 GB of free disk space for its installation. The memory\\nrequirements are likely to increase in the future, so please check the documentation at crc.dev for\\nmore up-to-date information.\\n7.3. Installation\\nTo install OpenShift Local, open your web browser and navigate to console.redhat.com/openshift/\\ncreate/local . Download the latest release of OpenShift Local and the \"pull secret\" file. The latter is a\\nfile containing a key identifying your copy of OpenShift Local to your Red Hat Developer account.\\nUnzip the file containing the OpenShift Local executable, and using your terminal, run the\\ncommand crc setup . This command will prepare your copy of OpenShift Local, verifying\\nrequirements and setting the required configuration values.\\nOnce the crc setup command is ready, launch crc start. Running crc start can take a long time,\\naround 20 minutes, on a recent PC.\\nOnce started, access the OpenShift Web Console with the crc console command, which will open\\nyour default browser. OpenShift Local uses the developer username and password to log in as a\\nlow-privilege user, while the kubeadmin user uses a random-generated password. Use the crc\\nconsole --credentials command to find the credentials required to log in as the kubeadmin user.\\nOpenShift Local allows developers to perform various everyday tasks as if it were a standard\\nOpenShift cluster, like deploying applications\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 2:\\nDocument_id:num-0\\nContent: .\\nThese characteristics set OpenShift apart as an excellent Kubernetes platform for enterprise users.\\nThe latest version of OpenShift available at the time of this writing is 4.12.\\n3.2. Is Red Hat OpenShift Open Source?\\nRed Hat OpenShift is a commercial product based on an open-source project called OKD. This\\nacronym means \" OpenShift Kubernetes Distribution\" and is publicly available for everyone to\\ninspect and contribute. Like the upstream Kubernetes project, OKD developers use the Go\\nprogramming language.\\n3.3. How can I run OpenShift?\\nToday, Red Hat OpenShift is available through various mechanisms and formats:\\n• DevOps teams can install it in their data centers \"on-premise.\"\\n• Major hyperscalers such as AWS, Azure, Google Cloud Platform, and IBM Cloud offer managed\\nRed Hat OpenShift installations.\\n• Developers can either run OpenShift locally on their workstations using Red Hat OpenShift\\nLocal, also known as CRC or \"Code-Ready Containers\"\\n• They can also request a 30-day trial OpenShift cluster, offered by Red Hat, at no charge, for\\ntesting and evaluation purposes.\\nRed Hat OpenShift is an integrated Platform-as-a-Service for enterprise users based on Kubernetes.\\nIt is tightly integrated with advanced security settings, developer tooling, and monitoring\\nmechanisms, allowing DevOps teams to be more productive.\\n8\\nChapter 4. OpenShift-only Custom Resource\\nDefinitions\\nRed Hat OpenShift is a complete DevOps platform extending Kubernetes in various ways. It bundles\\na constellation of Custom Resource Definitions \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCRDs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to make the life of developers and cluster\\nadministrators easier.\\nLet us talk first about the CRDs only available on OpenShift.\\n4.1. Project\\nAn OpenShift Project is similar to a Kubernetes namespace, but more tightly integrated into the\\nsecurity system of OpenShift through additional annotations.\\napiVersion: project.openshift.io/v1\\nkind: Project\\nmetadata:\\n\\xa0 name: linkedin-learning-project\\n\\xa0 annotations:\\n\\xa0   openshift.io/description: \"Project description\"\\n\\xa0   openshift.io/display-name: \"Display name\"\\n4.2. Route\\nThe OpenShift Route object was one of the primary inspirations during the development of the\\nIngress object. In OpenShift, Ingress and Route objects work together to ensure your applications\\nare available outside the cluster.\\napiVersion: route.openshift.io/v1\\nkind: Route\\nmetadata:\\n\\xa0 name: my-route\\nspec:\\n\\xa0 host:\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 3:\\nDocument_id:num-0\\nContent:  \"Import from Git\" entry. Click on it, and paste the URL of a project, for example,\\ngitlab.com/akosma/simple-deno-api.git.\\nAs soon as you paste the URL, OpenShift will immediately analyze the structure and programming\\nlanguage of the project and automatically recommend options for its build process. In our case, it’s\\na small application built with the Go programming language, and as such, it will advise the options\\nshown on the screen.\\nFigure 5. Deploying a project directly from its Git repository\\n25\\nThis particular example doesn’t require more configurations than the ones shown on the screen;\\nclick the \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\u2009Create\\u2009\u001b[0m\u001b[32m]\u001b[0m\u001b[32m button.\\nAfter a few seconds, you will see your application running on the \"Topology\" screen. OpenShift will\\ndownload the source code and trigger your project’s build. Click on the Topology screen icon to see\\nthe \"Build\" section, indicating that a build is running. The compilation and deployment of your\\napplication can take some time, depending on the complexity of the source code and the\\nprogramming language used.\\nOnce the build has finished, on the same pane, you will see a route available under the \"Routes\"\\nsection. Click on it, and you will see your application in action.\\n10.2. Container Registry\\nOpenShift has built your application source code, and the product of this build process is a\\ncontainer. You can see the container that OpenShift made for you on the \"Administrator\"\\nperspective, selecting the \"Builds\" menu and then the \"ImageStreams\" menu entry.\\nOpenShift includes a container registry; developers can use it as any other registry from outside the\\ncluster. Let us use \"podman\" to access the container registry and run the container locally on your\\nworkstation.\\nUsers must have the \"registry-editor\" and the \"system:image-builder\" roles to access the container\\nregistry. Since we’re connected to the Web Console using the \"kubeadmin\" user, we can provide\\nthose roles directly from the user interface without using the command line.\\nNavigate to the \"User Management\" section and select \"RoleBindings.\" Click on the \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\u2009Create\\nbinding\\u2009\u001b[0m\u001b[32m]\u001b[0m\u001b[32m button, and fill the form using the following values:\\n• Name: developer-sourcecode-registry-editor\\n• Namespace: sourcecode\\n• Role name: registry-editor\\n• Subject: User\\n• Subject name: developer\\nDo the same for the \"system:image-builder\" role, using a different \"Name\" field\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 4:\\nDocument_id:num-0\\nContent: 23\\ninstall OpenShift Local, 16\\nJ\\nJAR file, 23\\nJava, 14, 24, 44\\nJavaScript, 24, 44\\nJenkins, 28\\nK\\nKiali, 36\\nKibana, 40, 40\\nKnative, 34\\nKubernetes, 7\\nL\\nlogs, 40\\nM\\nMicroservices, 36\\nmonitor, 40\\nN\\nNode.js, 14\\nnon-root accounts, 20\\nO\\nOpenShift 4.12, 33\\nOpenShift Kubernetes Distribution, 8\\nOpenShift Service Mesh, 36\\noperator, 28, 36\\nOperatorHub, 33, 36\\nOperators, 33\\n48\\nP\\nperspectives, 22\\nPHP, 14, 24\\nPlatform-as-a-Service, 8\\nprivilege escalation, 19\\nprivileged ports, 20\\nProject, 9\\nPrometheus, 40, 44\\nPromQL, 45\\nPython, 14, 24, 44\\nQ\\nQuarkus, 14, 44\\nR\\nRed Hat developer account, 13\\nRed Hat OpenShift, 7\\nRed Hat OpenShift Dev Spaces, 14\\nRed Hat OpenShift Local, 8, 15\\nRed Hat OpenShift Pipelines, 28\\nRed Hat Quay, 20\\nRed Hat Universal Base Images, 19\\nrole, 19\\nRoute, 9\\nRust, 14\\nS\\nScala, 14\\nScaling, 42\\nsecure by default, 19\\nSecurity Context Constraints, 19\\nServerless, 34\\nservice mesh, 36\\nsource code project, 22\\nstateful applications, 33\\nT\\nTekton, 28\\ntemplates, 32\\nTopology, 27\\nTwelve-Factor App, 21, 40\\nTypeScript, 24\\nU\\nUBI, 19\\nV\\nVertical scaling, 42\\nVisual Studio Code, 14\\nW\\nWeb Console, 22, 40\\n49\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 5:\\nDocument_id:num-0\\nContent:  Git repository, for example, but not\\n22\\nlimited to GitHub, GitLab, Gitea, or other locations.\\n• Importing YAML directly or even a JAR file with a Java application.\\nLet us select the \"Container Image\" option, where we can specify the URL of a ready-to-use\\ncontainer.\\nEnter the URL of the container on the field, and click on the \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\u2009Create\\u2009\u001b[0m\u001b[32m]\u001b[0m\u001b[32m button at the bottom of the\\npage. You do not need to change any other value on the form.\\nA few seconds later, depending on the size of the container and the speed of your Internet\\nconnection, OpenShift will have pulled the container and deployed it onto your cluster. This\\ndeployment will include the usual standard elements: a \"Deployment\" object, a \"Service\" object, and\\na \"Route.\"\\nOpenShift offers a visual representation of the applications running on your project: click on the\\nicon of your container, and you will see a panel opening on the right side of the screen. This panel\\nwill include the URL automatically assigned to your deployment, and clicking it will show the\\napplication in action in another browser tab.\\nFigure 4. Topology screen on Red Hat OpenShift\\n9.2. Creating and Debugging Applications with the odo\\nTool\\nWith the oc tool, Red Hat provides another one geared toward software developers: the odo tool.\\nDevelopers can use the odo tool to create applications using \"Devfiles,\" particular files named\\n\"devfile.yaml\" based on an open standard available at the Devfiles website. Devfiles contain\\ninformation about your application’s programming language, dependencies, and other essential\\ndetails.\\n23\\nThe odo tool is not available by default on your command line, but you can download it from the\\n\"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry. Click on the\\n\"Download odo\" link at the bottom, and select the version of odo that corresponds to your system.\\nThe \"odo catalog list components was\" command shows the various programming languages and\\nframeworks supported off-the-box by \"odo.\"\\nThe odo init  command prompts the user for a new application using many programming\\nlanguages: .NET, Go, Java, JavaScript, PHP, Python, and TypeScript. The last command generates a\\nscaffold ready to be populated with the required logic. Finally, the odo push command builds and\\npushes the container to the OpenShift container registry, deploying\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'END of knowledge_search tool results.\\n'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'The above results were retrieved to help answer the user\\'s query: \"installing OpenShift\". Use them as supporting information only in answering this query.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[33mBased on the provided text, here is an answer to the query:\n",
      "\n",
      "To install Red Hat OpenShift, you can follow these steps:\n",
      "\n",
      "1. Download and install the oc tool from the Red Hat website or through the \"Help\" menu on the OpenShift Web Console.\n",
      "2. Install OpenShift Local by downloading a JAR file and running it with Java.\n",
      "3. Use the oc tool to create a new project and import a Git repository, YAML file, or container image into your project.\n",
      "\n",
      "Alternatively, you can use the odo tool provided by Red Hat to create applications using Devfiles. To do this:\n",
      "\n",
      "1. Download the odo tool from the \"Help\" menu on the OpenShift Web Console.\n",
      "2. Use the odo init command to prompt for a new application and select a programming language.\n",
      "3. The odo push command builds and pushes the container to the OpenShift container registry, deploying it onto your cluster.\n",
      "\n",
      "Note: These steps assume you have a Red Hat developer account and access to the OpenShift Web Console.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"How to install OpenShift?\",\n",
    "]\n",
    "\n",
    "# initializing the agent\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    sampling_params=sampling_params,\n",
    "    # we make our agent aware of the RAG tool by including builtin::rag/knowledge_search in the list of tools\n",
    "    tools=[\n",
    "        dict(\n",
    "            name=\"builtin::rag/knowledge_search\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [vector_db_id],  # list of IDs of document collections to consider during retrieval\n",
    "            },\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "for prompt in queries:\n",
    "    cprint(f\"\\nUser> {prompt}\", \"blue\")\n",
    "    \n",
    "    # create a new turn with a new session ID for each prompt\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=agent.create_session(f\"rag-session_{uuid.uuid4()}\"),\n",
    "        stream=stream,\n",
    "    )\n",
    "    \n",
    "    # print the response, including tool calls output\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6937a3-3efa-4b66-aaf0-85d96b6d43db",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "This tutorial demonstrates how to implement agentic RAG with Llama Stack. We do so by initializing an agent while giving it access to the RAG tool, then invoking the agent on each of the specified queries. Please check out our [complementary tutorial](demos/rag_agentic/notebooks/Level1_foundational_RAG.ipynb) for a non-agentic RAG example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
